{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1FpPVYDdAhOww7na2Wy_MhErDIkcN7HWF","authorship_tag":"ABX9TyMWB85T+i47jS8tL0MaPxM3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import csv\n","import pandas as pd\n","import numpy as np\n","from sklearn.utils import resample\n","import sys"],"metadata":{"id":"47RTCVyndQOE","executionInfo":{"status":"ok","timestamp":1748875777310,"user_tz":-480,"elapsed":1047,"user":{"displayName":"Xinyu Gong","userId":"11369812454076413949"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8LAlscmcne3","executionInfo":{"status":"ok","timestamp":1748875816291,"user_tz":-480,"elapsed":36482,"user":{"displayName":"Xinyu Gong","userId":"11369812454076413949"}},"outputId":"284693cf-d5e4-4241-f04e-c38eaa1a6873"},"outputs":[{"output_type":"stream","name":"stdout","text":["文件: Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv, 行数: 225746, 列数: 79\n","文件: Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv, 行数: 286468, 列数: 79\n","文件: Friday-WorkingHours-Morning.pcap_ISCX.csv, 行数: 191034, 列数: 79\n","文件: Monday-WorkingHours.pcap_ISCX.csv, 行数: 529919, 列数: 79\n","文件: Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv, 行数: 288603, 列数: 79\n","文件: Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv, 行数: 170367, 列数: 79\n","文件: Tuesday-WorkingHours.pcap_ISCX.csv, 行数: 445910, 列数: 79\n","文件: Wednesday-workingHours.pcap_ISCX.csv, 行数: 692704, 列数: 79\n"]}],"source":["folder_path=\"/content/drive/MyDrive/XAI_DATA/MachineLearningCVE\"\n","    # 获取所有CSV文件（不区分大小写）\n","csv_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.csv')]\n","\n","for filename in csv_files:\n","    filepath = os.path.join(folder_path, filename)\n","    row_count = 0\n","    col_count = 0\n","\n","            # 尝试使用UTF-8编码打开文件\n","    with open(filepath, 'r', newline='', encoding='utf-8') as csvfile:\n","        reader = csv.reader(csvfile)\n","        try:\n","            for row in reader:\n","                if row_count == 0:\n","                    col_count = len(row)\n","                row_count += 1\n","        except csv.Error as e:\n","            print(f\"解析文件 {filename} 时出错: {e}\")\n","\n","\n","        # 输出结果\n","    print(f\"文件: {filename}, 行数: {row_count}, 列数: {col_count}\")\n"]},{"cell_type":"code","source":["import os\n","import re\n","import pandas as pd\n","\n","# 原始文件夹路径\n","folder_path = \"/content/drive/MyDrive/XAI_DATA/Balanced TCP-IP Layer\"\n","# 新文件夹路径（可选：保存添加超时值后的文件）\n","output_folder = \"/content/drive/MyDrive/XAI_DATA/Processed_TCP-IP\"\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# 用于存储所有DataFrame的列表\n","all_dfs = []\n","\n","# 正则表达式提取超时值（格式：_数字s.csv）\n","pattern = re.compile(r'_(\\d+)s\\.csv$', re.IGNORECASE)\n","\n","for filename in os.listdir(folder_path):\n","    if not filename.lower().endswith('.csv'):\n","        continue\n","\n","    # 从文件名提取超时值\n","    match = pattern.search(filename)\n","    if not match:\n","        print(f\"跳过无法解析超时值的文件: {filename}\")\n","        continue\n","    timeout = int(match.group(1))\n","\n","    # 构建完整路径\n","    filepath = os.path.join(folder_path, filename)\n","\n","    try:\n","        # 读取CSV文件（自动处理编码问题）\n","        df = pd.read_csv(filepath, encoding_errors='replace')  # 自动替换解码错误字符\n","\n","        # 添加超时值列\n","        df['flow timeout'] = timeout\n","\n","        # （可选）保存修改后的文件\n","        output_path = os.path.join(output_folder, filename)\n","        df.to_csv(output_path, index=False)\n","\n","        # 添加到合并列表\n","        all_dfs.append(df)\n","        print(f\"已处理: {filename} | 超时值: {timeout}s | 记录数: {len(df)}\")\n","\n","    except Exception as e:\n","        print(f\"处理文件 {filename} 失败: {str(e)}\")\n","        continue\n","\n","# 合并所有DataFrame\n","if all_dfs:\n","    merged_df = pd.concat(all_dfs, ignore_index=True)\n","\n","    # 保存合并后的文件\n","    merged_path = os.path.join(output_folder, \"combined_tcpip_dataset.csv\")\n","    merged_df.to_csv(merged_path, index=False)\n","    print(f\"\\n合并完成！总记录数: {len(merged_df)}\")\n","    print(f\"合并文件保存至: {merged_path}\")\n","else:\n","    print(\"没有找到可处理的CSV文件！\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HSO_BK76xLn","executionInfo":{"status":"ok","timestamp":1747966474750,"user_tz":-480,"elapsed":4714,"user":{"displayName":"Xinyu Gong","userId":"11369812454076413949"}},"outputId":"7e2f52f0-4ff5-4d61-bb0b-3f2bd7df2d98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["已处理: Testing_120s.csv | 超时值: 120s | 记录数: 558\n","已处理: Testing_20s.csv | 超时值: 20s | 记录数: 3086\n","已处理: Testing_15s.csv | 超时值: 15s | 记录数: 3086\n","已处理: Training_120s.csv | 超时值: 120s | 记录数: 1302\n","已处理: Testing_60s.csv | 超时值: 60s | 记录数: 1040\n","已处理: Training_15s.csv | 超时值: 15s | 记录数: 7199\n","已处理: Training_240s.csv | 超时值: 240s | 记录数: 668\n","已处理: Training_20s.csv | 超时值: 20s | 记录数: 7199\n","已处理: Testing_240s.csv | 超时值: 240s | 记录数: 287\n","已处理: Training_60s.csv | 超时值: 60s | 记录数: 2425\n","跳过无法解析超时值的文件: merged.csv\n","\n","合并完成！总记录数: 26850\n","合并文件保存至: /content/drive/MyDrive/XAI_DATA/Processed_TCP-IP/combined_tcpip_dataset.csv\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from glob import glob\n","\n","# 设置参数\n","input_folder = '/content/drive/MyDrive/XAI_DATA/MachineLearningCVE'  # 需要合并的CSV文件夹路径\n","output_file = '/content/drive/MyDrive/XAI_DATA/MachineLearningCVE/CIC2017.csv'  # 输出文件路径\n","file_pattern = '*.csv'       # 文件匹配模式（默认所有csv文件）\n","\n","# 获取所有CSV文件列表\n","all_files = glob(os.path.join(input_folder, file_pattern))\n","\n","# 验证找到文件\n","if not all_files:\n","    print(f\"在 {input_folder} 中未找到{file_pattern}文件\")\n","    exit()\n","\n","# 存储各个DataFrame的列表\n","df_list = []\n","\n","# 遍历并读取所有CSV文件\n","for file in all_files:\n","    try:\n","        # 读取CSV文件（可根据需要调整参数）\n","        df = pd.read_csv(file, encoding='utf-8')\n","\n","        # 记录文件信息\n","        print(f\"正在处理：{os.path.basename(file)} ({len(df)} 行)\")\n","\n","        # 添加到列表\n","        df_list.append(df)\n","    except Exception as e:\n","        print(f\"处理 {file} 时出错：{str(e)}\")\n","        continue\n","\n","# 合并所有DataFrame\n","if df_list:\n","    try:\n","        merged_df = pd.concat(df_list, ignore_index=True)\n","\n","        # 保存合并后的文件\n","        merged_df.to_csv(output_file, index=False, encoding='utf-8')\n","        print(f\"\\n合并完成！共合并 {len(all_files)} 个文件\")\n","        print(f\"总行数：{len(merged_df)}\")\n","        print(f\"已保存至：{os.path.abspath(output_file)}\")\n","    except Exception as e:\n","        print(f\"合并过程中出错：{str(e)}\")\n","else:\n","    print(\"没有有效数据可以合并\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cARV5kdmcvCn","executionInfo":{"status":"ok","timestamp":1748876180245,"user_tz":-480,"elapsed":155565,"user":{"displayName":"Xinyu Gong","userId":"11369812454076413949"}},"outputId":"b0e77f89-5209-45b1-b1c5-6607e2e106b1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["正在处理：Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv (225745 行)\n","正在处理：Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv (286467 行)\n","正在处理：Friday-WorkingHours-Morning.pcap_ISCX.csv (191033 行)\n","正在处理：Monday-WorkingHours.pcap_ISCX.csv (529918 行)\n","正在处理：Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv (288602 行)\n","正在处理：Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv (170366 行)\n","正在处理：Tuesday-WorkingHours.pcap_ISCX.csv (445909 行)\n","正在处理：Wednesday-workingHours.pcap_ISCX.csv (692703 行)\n","\n","合并完成！共合并 8 个文件\n","总行数：2830743\n","已保存至：/content/drive/MyDrive/XAI_DATA/MachineLearningCVE/CIC2017.csv\n"]}]}]}