{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Galaxy2023666/XAI/blob/main/5G_NIDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPolDyItP5Z3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix, classification_report,\n",
        "                             ConfusionMatrixDisplay)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# !pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from xgboost import XGBClassifier, XGBRegressor, plot_importance, plot_tree\n",
        "\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zLffwZ02LwiI"
      },
      "outputs": [],
      "source": [
        "# 1. read CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/XAI_DATA/Combined.csv',encoding='utf-8')\n",
        "\n",
        "# 2. show the sample data\n",
        "print(\"data sampleï¼š\")\n",
        "print(df.head())\n",
        "\n",
        "# 3. basic info\n",
        "print(\"\\nbasic infoï¼š\")\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "# handle NaN\n",
        "print(df.info())\n",
        "MIN_NON_NULL=1215000\n",
        "df_cleaned = df.dropna(axis=1, thresh=MIN_NON_NULL)\n",
        "print(df_cleaned.info())\n",
        "\n",
        "# object\n",
        "object_cols = df_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
        "print(f\"Objectï¼ˆ{len(object_cols)}ï¼‰ï¼š\\n{object_cols}\")\n",
        "\n",
        "analysis_report = pd.DataFrame({\n",
        "        'column': object_cols,\n",
        "        'unique': [df[col].nunique() for col in object_cols],\n",
        "        'Nan': [df[col].isnull().sum() for col in object_cols],\n",
        "        'Nan rate': [df[col].isnull().mean().round(4) for col in object_cols],\n",
        "        'frequency': [df[col].mode()[0] if not df[col].empty else np.nan for col in object_cols],\n",
        "        'frequency rate': [round(df[col].value_counts(normalize=True).iloc[0], 4) for col in object_cols],\n",
        "        'sample': [df[col].dropna().iloc[0] if not df[col].dropna().empty else np.nan for col in object_cols]\n",
        "})\n",
        "\n",
        "print(\"\\nObjectï¼š\")\n",
        "display(analysis_report.sort_values('unique', ascending=False))\n",
        "\n",
        "for col in object_cols:\n",
        "    value_counts = df[col].value_counts(dropna=False)\n",
        "    unique_count = len(value_counts)\n",
        "\n",
        "    print(f\"\\n=== columnã€{col}ã€‘ ===\")\n",
        "    print(f\"unique{unique_count}\")\n",
        "    print(value_counts.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rYw5F4Y9vL5P"
      },
      "outputs": [],
      "source": [
        "# data processing\n",
        "# merge some categories\n",
        "df_cleaned['Proto'] = np.where(df_cleaned['Proto'].isin(['lldp','llc','arp','ipv6-icmp']), 'other', df_cleaned['Proto'])\n",
        "df_cleaned['State'] = np.where(df_cleaned['State'].isin(['ECO','ACC','URP','RSP','TST','NRS']), 'other', df_cleaned['State'])\n",
        "\n",
        "# # encode\n",
        "# proto_freq = df['Proto'].value_counts(normalize=True)\n",
        "# df['Proto_encoded'] = df['Proto'].map(proto_freq)\n",
        "proto_dummies = pd.get_dummies(df_cleaned['Proto'], prefix='Proto')\n",
        "cause_dummies = pd.get_dummies(df_cleaned['Cause'], prefix='Cause')\n",
        "state_dummies = pd.get_dummies(df_cleaned['State'], prefix='State')\n",
        "df_new = pd.concat([df_cleaned, proto_dummies, cause_dummies,state_dummies], axis=1)\n",
        "df_new.drop(['Proto', 'Cause','State','sDSb'], axis=1, inplace=True)\n",
        "df_new=df_new.dropna(axis=0)\n",
        "print(df_new.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV82xhDR7npQ"
      },
      "outputs": [],
      "source": [
        "features=df_new.columns.tolist()\n",
        "features.remove('Label')\n",
        "features.remove('Attack Type')\n",
        "features.remove('Attack Tool')\n",
        "features.remove('Unnamed: 0')\n",
        "print(features)\n",
        "X = df_new[features]\n",
        "le = LabelEncoder()\n",
        "y = df_new['Label']\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdcIMd8G1PwF"
      },
      "outputs": [],
      "source": [
        "label_counts = df_new['Label'].value_counts()\n",
        "print(label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM525t-qoBi5"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Tuple, Optional, Union\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class XAIAnalyzer:\n",
        "    \"\"\"\n",
        "    XAIå¯è§£é‡Šæ€§åˆ†æå™¨ï¼Œé›†æˆSHAPå’ŒLIMEåŠŸèƒ½\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, X_train: pd.DataFrame, class_names: List[str] = None):\n",
        "        \"\"\"\n",
        "        åˆå§‹åŒ–XAIåˆ†æå™¨\n",
        "\n",
        "        Args:\n",
        "            model: è®­ç»ƒå¥½çš„æœºå™¨å­¦ä¹ æ¨¡å‹\n",
        "            X_train: è®­ç»ƒæ•°æ®ç‰¹å¾\n",
        "            class_names: ç±»åˆ«åç§°åˆ—è¡¨\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.X_train = X_train\n",
        "        self.class_names = class_names or [f'Class_{i}' for i in range(2)]\n",
        "        self.explainer = None\n",
        "        self.lime_explainer = None\n",
        "\n",
        "    def _create_shap_explainer(self, sample_size: int = 100):\n",
        "        \"\"\"åˆ›å»ºSHAPè§£é‡Šå™¨\"\"\"\n",
        "        if self.explainer is None:\n",
        "            sample_data = shap.sample(self.X_train, min(sample_size, len(self.X_train)))\n",
        "            self.explainer = shap.KernelExplainer(self.model.predict, sample_data)\n",
        "        return self.explainer\n",
        "\n",
        "    def _create_lime_explainer(self):\n",
        "        \"\"\"åˆ›å»ºLIMEè§£é‡Šå™¨\"\"\"\n",
        "        if self.lime_explainer is None:\n",
        "            self.lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "                training_data=self.X_train.values,\n",
        "                feature_names=self.X_train.columns.tolist(),\n",
        "                class_names=self.class_names,\n",
        "                mode='classification'\n",
        "            )\n",
        "        return self.lime_explainer\n",
        "\n",
        "    def generate_shap_summary_plots(self, X_test: pd.DataFrame, max_samples: int = 1000):\n",
        "        \"\"\"\n",
        "        ç”ŸæˆSHAPæ€»ä½“åˆ†æå›¾ï¼ˆbar plotå’Œbeeswarm plotï¼‰\n",
        "\n",
        "        Args:\n",
        "            X_test: æµ‹è¯•æ•°æ®\n",
        "            max_samples: æœ€å¤§æ ·æœ¬æ•°é‡\n",
        "        \"\"\"\n",
        "        print(\"æ­£åœ¨ç”ŸæˆSHAPæ€»ä½“åˆ†æå›¾...\")\n",
        "\n",
        "        # åˆ›å»ºè§£é‡Šå™¨\n",
        "        explainer = self._create_shap_explainer()\n",
        "\n",
        "        # é™åˆ¶æ ·æœ¬æ•°é‡ä»¥æé«˜æ€§èƒ½\n",
        "        test_sample = X_test.iloc[:min(max_samples, len(X_test))]\n",
        "\n",
        "        # è®¡ç®—SHAPå€¼\n",
        "        print(f\"æ­£åœ¨è®¡ç®— {len(test_sample)} ä¸ªæ ·æœ¬çš„SHAPå€¼...\")\n",
        "        shap_values = explainer.shap_values(test_sample)\n",
        "\n",
        "        # ç”Ÿæˆsummary plot - bar plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values, test_sample, plot_type=\"bar\", show=False)\n",
        "        plt.title(\"SHAP Feature Importance (Bar Plot)\", fontsize=14, pad=20)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ç”Ÿæˆsummary plot - beeswarm plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values, test_sample, show=False)\n",
        "        plt.title(\"SHAP Feature Effects (Beeswarm Plot)\", fontsize=14, pad=20)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return shap_values\n",
        "\n",
        "    def find_wrong_predictions(self, X_test: pd.DataFrame, y_test: pd.Series) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        æ‰¾å‡ºæ¨¡å‹çš„é”™è¯¯é¢„æµ‹\n",
        "\n",
        "        Args:\n",
        "            X_test: æµ‹è¯•ç‰¹å¾\n",
        "            y_test: æµ‹è¯•æ ‡ç­¾\n",
        "\n",
        "        Returns:\n",
        "            wrong_indices: é”™è¯¯é¢„æµ‹çš„ç´¢å¼•\n",
        "            y_pred: æ‰€æœ‰é¢„æµ‹ç»“æœ\n",
        "        \"\"\"\n",
        "        print(\"æ­£åœ¨åˆ†ææ¨¡å‹é¢„æµ‹ç»“æœ...\")\n",
        "\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        wrong_indices = np.where(y_pred != y_test)[0]\n",
        "\n",
        "        print(f\"æ€»æ ·æœ¬æ•°: {len(y_test)}\")\n",
        "        print(f\"é”™è¯¯é¢„æµ‹æ•°: {len(wrong_indices)}\")\n",
        "        print(f\"é”™è¯¯ç‡: {len(wrong_indices)/len(y_test):.2%}\")\n",
        "\n",
        "        if len(wrong_indices) > 0:\n",
        "            print(f\"é”™è¯¯é¢„æµ‹æ ·æœ¬ç´¢å¼•: {wrong_indices[:10]}...\" if len(wrong_indices) > 10 else f\"é”™è¯¯é¢„æµ‹æ ·æœ¬ç´¢å¼•: {wrong_indices}\")\n",
        "\n",
        "        return wrong_indices, y_pred\n",
        "\n",
        "    def analyze_wrong_predictions_shap(self, X_test: pd.DataFrame, y_test: pd.Series,\n",
        "                                     max_samples: int = 5, class_index: Optional[int] = None):\n",
        "        \"\"\"\n",
        "        ä½¿ç”¨SHAPåˆ†æé”™è¯¯é¢„æµ‹æ ·æœ¬\n",
        "\n",
        "        Args:\n",
        "            X_test: æµ‹è¯•ç‰¹å¾\n",
        "            y_test: æµ‹è¯•æ ‡ç­¾\n",
        "            max_samples: åˆ†æçš„æœ€å¤§æ ·æœ¬æ•°\n",
        "            class_index: æŒ‡å®šåˆ†æçš„ç±»åˆ«ç´¢å¼•ï¼ˆå¤šåˆ†ç±»æ—¶ä½¿ç”¨ï¼‰\n",
        "        \"\"\"\n",
        "        wrong_indices, y_pred = self.find_wrong_predictions(X_test, y_test)\n",
        "\n",
        "        if len(wrong_indices) == 0:\n",
        "            print(\"ğŸ‰ æ¨¡å‹æ²¡æœ‰é”™è¯¯é¢„æµ‹ï¼\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nğŸ“Š æ­£åœ¨åˆ†æå‰ {min(max_samples, len(wrong_indices))} ä¸ªé”™è¯¯é¢„æµ‹æ ·æœ¬çš„SHAPè§£é‡Š...\")\n",
        "\n",
        "        # åˆ›å»ºè§£é‡Šå™¨\n",
        "        explainer = self._create_shap_explainer()\n",
        "\n",
        "        # é€‰æ‹©è¦åˆ†æçš„æ ·æœ¬\n",
        "        sample_indices = wrong_indices[:max_samples] if len(wrong_indices) > max_samples else wrong_indices\n",
        "        X_wrong = X_test.iloc[sample_indices]\n",
        "\n",
        "        # è®¡ç®—SHAPå€¼\n",
        "        shap_values = explainer.shap_values(X_wrong)\n",
        "\n",
        "        # ä¸ºæ¯ä¸ªé”™è¯¯æ ·æœ¬ç”Ÿæˆwaterfallå›¾\n",
        "        for i, idx in enumerate(sample_indices):\n",
        "            self._plot_single_shap_waterfall(explainer, shap_values, X_test, y_test,\n",
        "                                           y_pred, idx, i, class_index)\n",
        "\n",
        "    def _plot_single_shap_waterfall(self, explainer, shap_values, X_test, y_test,\n",
        "                                  y_pred, idx, i, class_index):\n",
        "        \"\"\"ç»˜åˆ¶å•ä¸ªæ ·æœ¬çš„SHAP waterfallå›¾\"\"\"\n",
        "        print(f\"\\næ ·æœ¬ {idx}:\")\n",
        "        print(f\"çœŸå®æ ‡ç­¾: {y_test.iloc[idx] if hasattr(y_test, 'iloc') else y_test[idx]} ({self.class_names[y_test.iloc[idx] if hasattr(y_test, 'iloc') else y_test[idx]]})\")\n",
        "        print(f\"é¢„æµ‹æ ‡ç­¾: {y_pred[idx]} ({self.class_names[y_pred[idx]]})\")\n",
        "\n",
        "        # å¤„ç†å¤šåˆ†ç±»å’ŒäºŒåˆ†ç±»æƒ…å†µ\n",
        "        if isinstance(shap_values, list):\n",
        "            # å¤šåˆ†ç±»æ¨¡å‹\n",
        "            target_class = class_index if class_index is not None else y_pred[idx]\n",
        "            values = shap_values[target_class][i]\n",
        "            base_value = explainer.expected_value[target_class]\n",
        "            plot_title = f\"æ ·æœ¬ {idx} - {self.class_names[target_class]} ç±»åˆ«çš„SHAPè§£é‡Š\"\n",
        "        else:\n",
        "            # äºŒåˆ†ç±»æ¨¡å‹\n",
        "            values = shap_values[i]\n",
        "            base_value = explainer.expected_value\n",
        "            plot_title = f\"æ ·æœ¬ {idx} - SHAPè§£é‡Š\"\n",
        "\n",
        "        # åˆ›å»ºè§£é‡Šå¯¹è±¡\n",
        "        explanation = shap.Explanation(\n",
        "            values=values,\n",
        "            base_values=base_value,\n",
        "            data=X_test.iloc[idx],\n",
        "            feature_names=X_test.columns.tolist()\n",
        "        )\n",
        "\n",
        "        # ç»˜åˆ¶waterfallå›¾\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.waterfall_plot(explanation, show=False)\n",
        "        plt.title(plot_title, fontsize=14, pad=20)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def analyze_wrong_predictions_lime(self, X_test: pd.DataFrame, y_test: pd.Series,\n",
        "                                     max_samples: int = 5, num_features: int = 10):\n",
        "        \"\"\"\n",
        "        ä½¿ç”¨LIMEåˆ†æé”™è¯¯é¢„æµ‹æ ·æœ¬\n",
        "\n",
        "        Args:\n",
        "            X_test: æµ‹è¯•ç‰¹å¾\n",
        "            y_test: æµ‹è¯•æ ‡ç­¾\n",
        "            max_samples: åˆ†æçš„æœ€å¤§æ ·æœ¬æ•°\n",
        "            num_features: LIMEè§£é‡Šä¸­æ˜¾ç¤ºçš„ç‰¹å¾æ•°é‡\n",
        "        \"\"\"\n",
        "        wrong_indices, y_pred = self.find_wrong_predictions(X_test, y_test)\n",
        "\n",
        "        if len(wrong_indices) == 0:\n",
        "            print(\"ğŸ‰ æ¨¡å‹æ²¡æœ‰é”™è¯¯é¢„æµ‹ï¼\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nğŸ” æ­£åœ¨åˆ†æå‰ {min(max_samples, len(wrong_indices))} ä¸ªé”™è¯¯é¢„æµ‹æ ·æœ¬çš„LIMEè§£é‡Š...\")\n",
        "\n",
        "        # åˆ›å»ºLIMEè§£é‡Šå™¨\n",
        "        lime_explainer = self._create_lime_explainer()\n",
        "\n",
        "        # é€‰æ‹©è¦åˆ†æçš„æ ·æœ¬\n",
        "        sample_indices = wrong_indices[:max_samples] if len(wrong_indices) > max_samples else wrong_indices\n",
        "\n",
        "        # ä¸ºæ¯ä¸ªé”™è¯¯æ ·æœ¬ç”ŸæˆLIMEè§£é‡Š\n",
        "        for idx in sample_indices:\n",
        "            print(f\"\\n--- æ ·æœ¬ {idx} çš„LIMEè§£é‡Š ---\")\n",
        "            print(f\"çœŸå®æ ‡ç­¾: {y_test.iloc[idx] if hasattr(y_test, 'iloc') else y_test[idx]} ({self.class_names[y_test.iloc[idx] if hasattr(y_test, 'iloc') else y_test[idx]]})\")\n",
        "            print(f\"é¢„æµ‹æ ‡ç­¾: {y_pred[idx]} ({self.class_names[y_pred[idx]]})\")\n",
        "\n",
        "            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰predict_probaæ–¹æ³•\n",
        "            if hasattr(self.model, 'predict_proba'):\n",
        "                prediction_fn = self.model.predict_proba\n",
        "            else:\n",
        "                # å¦‚æœæ²¡æœ‰predict_probaï¼Œåˆ›å»ºä¸€ä¸ªåŒ…è£…å‡½æ•°\n",
        "                def prediction_fn(X):\n",
        "                    preds = self.model.predict(X)\n",
        "                    # è½¬æ¢ä¸ºæ¦‚ç‡æ ¼å¼ï¼ˆç®€å•çš„one-hotç¼–ç ï¼‰\n",
        "                    proba = np.zeros((len(preds), len(self.class_names)))\n",
        "                    for i, pred in enumerate(preds):\n",
        "                        proba[i, pred] = 1.0\n",
        "                    return proba\n",
        "\n",
        "            try:\n",
        "                # ç”ŸæˆLIMEè§£é‡Š\n",
        "                exp = lime_explainer.explain_instance(\n",
        "                    X_test.iloc[idx].values,\n",
        "                    prediction_fn,\n",
        "                    num_features=min(num_features, len(X_test.columns))\n",
        "                )\n",
        "\n",
        "                # æ˜¾ç¤ºè§£é‡Š\n",
        "                exp.show_in_notebook(show_table=True)\n",
        "\n",
        "                # ä¹Ÿå¯ä»¥ä¿å­˜ä¸ºå›¾ç‰‡ï¼ˆå¯é€‰ï¼‰\n",
        "                # fig = exp.as_pyplot_figure()\n",
        "                # plt.title(f'LIMEè§£é‡Š - æ ·æœ¬ {idx}')\n",
        "                # plt.tight_layout()\n",
        "                # plt.show()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"ç”Ÿæˆæ ·æœ¬ {idx} çš„LIMEè§£é‡Šæ—¶å‡ºé”™: {str(e)}\")\n",
        "\n",
        "    def complete_xai_analysis(self, X_test: pd.DataFrame, y_test: pd.Series,\n",
        "                            max_summary_samples: int = 1000, max_wrong_samples: int = 5,\n",
        "                            lime_features: int = 10, class_index: Optional[int] = None):\n",
        "        \"\"\"\n",
        "        å®Œæ•´çš„XAIåˆ†ææµç¨‹\n",
        "\n",
        "        Args:\n",
        "            X_test: æµ‹è¯•ç‰¹å¾\n",
        "            y_test: æµ‹è¯•æ ‡ç­¾\n",
        "            max_summary_samples: ç”Ÿæˆæ€»ä½“å›¾çš„æœ€å¤§æ ·æœ¬æ•°\n",
        "            max_wrong_samples: åˆ†æé”™è¯¯é¢„æµ‹çš„æœ€å¤§æ ·æœ¬æ•°\n",
        "            lime_features: LIMEè§£é‡Šæ˜¾ç¤ºçš„ç‰¹å¾æ•°\n",
        "            class_index: å¤šåˆ†ç±»æ—¶æŒ‡å®šåˆ†æçš„ç±»åˆ«\n",
        "        \"\"\"\n",
        "        print(\"ğŸš€ å¼€å§‹å®Œæ•´çš„XAIå¯è§£é‡Šæ€§åˆ†æ...\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # 1. ç”ŸæˆSHAPæ€»ä½“åˆ†æå›¾\n",
        "        print(\"ğŸ“ˆ ç¬¬ä¸€æ­¥: ç”ŸæˆSHAPæ€»ä½“åˆ†æå›¾\")\n",
        "        self.generate_shap_summary_plots(X_test, max_summary_samples)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "        # 2. åˆ†æé”™è¯¯é¢„æµ‹ - SHAP\n",
        "        print(\"ğŸ” ç¬¬äºŒæ­¥: ä½¿ç”¨SHAPåˆ†æé”™è¯¯é¢„æµ‹\")\n",
        "        self.analyze_wrong_predictions_shap(X_test, y_test, max_wrong_samples, class_index)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "        # 3. åˆ†æé”™è¯¯é¢„æµ‹ - LIME\n",
        "        print(\"ğŸ” ç¬¬ä¸‰æ­¥: ä½¿ç”¨LIMEåˆ†æé”™è¯¯é¢„æµ‹\")\n",
        "        self.analyze_wrong_predictions_lime(X_test, y_test, max_wrong_samples, lime_features)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"âœ… XAIåˆ†æå®Œæˆï¼\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3CJ6FWatwE_"
      },
      "source": [
        "After having a total view of the dataset, the next step will be using different ML model to build the detection system.\n",
        "Here we choose different models:\n",
        "\n",
        "1.   Decision Trees\n",
        "2.   Random Forests\n",
        "\n",
        "1.   Multilayer Perceptron\n",
        "2.   DNN\n",
        "\n",
        "1.   XGBoost\n",
        "2.   BiLSTM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esxi-OrcttDx"
      },
      "outputs": [],
      "source": [
        "#DT\n",
        "# divide data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "## grid search\n",
        "# param_grid = {\n",
        "#     'max_depth': [3, 5, 7, None],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "#     'class_weight': [None, 'balanced']\n",
        "# }\n",
        "\n",
        "# grid_search = GridSearchCV(\n",
        "#     estimator=dt,\n",
        "#     param_grid=param_grid,\n",
        "#     scoring='roc_auc',\n",
        "#     cv=5,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# best_dt = grid_search.best_estimator_\n",
        "# print(f\"best parasï¼š{grid_search.best_params_}\")\n",
        "# print(f\"best AUCï¼š{grid_search.best_score_:.4f}\")\n",
        "\n",
        "best_dt=dt.fit(X_train, y_train)\n",
        "\n",
        "# model eval\n",
        "def evaluate_model(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    y_proba = model.predict_proba(X)[:, 1]\n",
        "\n",
        "    print(f\"accuracyï¼š{accuracy_score(y, y_pred):.4f}\")\n",
        "    print(f\"precisionï¼š{precision_score(y, y_pred):.4f}\")\n",
        "    print(f\"recallï¼š{recall_score(y, y_pred):.4f}\")\n",
        "    print(f\"F1ï¼š{f1_score(y, y_pred):.4f}\")\n",
        "    print(f\"AUCï¼š{roc_auc_score(y, y_proba):.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot()\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\ntrainï¼š\")\n",
        "evaluate_model(best_dt, X_train, y_train)\n",
        "\n",
        "print(\"\\ntestï¼š\")\n",
        "evaluate_model(best_dt, X_test, y_test)\n",
        "\n",
        "# feature importance\n",
        "feature_importance = pd.Series(best_dt.feature_importances_, index=features)\n",
        "feature_importance.sort_values().plot(kind='barh')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(20, 10))\n",
        "from sklearn.tree import plot_tree\n",
        "plot_tree(\n",
        "    best_dt,\n",
        "    feature_names=features,\n",
        "    class_names=['Class 0', 'Class 1'],\n",
        "    filled=True,\n",
        "    proportion=True,\n",
        "    max_depth=3\n",
        ")\n",
        "plt.title('Decision Tree Structure')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnutOTxm59kj"
      },
      "outputs": [],
      "source": [
        "# ä½¿ç”¨ç¤ºä¾‹\n",
        "# 1. åˆ›å»ºåˆ†æå™¨\n",
        "analyzer = XAIAnalyzer(best_dt, X_train, class_names=le.classes_.tolist())\n",
        "\n",
        "# 2. æ‰§è¡Œå®Œæ•´åˆ†æï¼ˆæ¨èï¼‰\n",
        "analyzer.complete_xai_analysis(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crUjy8ERKMEw"
      },
      "outputs": [],
      "source": [
        "#RF\n",
        "\n",
        "rf_classifier = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# train\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# prediction\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "#feature importance\n",
        "feature_importances = pd.Series(\n",
        "    rf_classifier.feature_importances_,  # or rf_regressor\n",
        "    index=X.columns\n",
        ")\n",
        "feature_importances = feature_importances.sort_values(ascending=False)\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "feature_importances.plot(kind='bar')\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5K8YlhlTJ1N"
      },
      "outputs": [],
      "source": [
        "# 1. åˆ›å»ºåˆ†æå™¨\n",
        "analyzer = XAIAnalyzer(rf_classifier, X_train, class_names=le.classes_.tolist())\n",
        "\n",
        "# 2. æ‰§è¡Œå®Œæ•´åˆ†æï¼ˆæ¨èï¼‰\n",
        "analyzer.complete_xai_analysis(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AileZ3fNNCQc"
      },
      "outputs": [],
      "source": [
        "#MLP\n",
        "mlp_clf = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=500,\n",
        "    random_state=42,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1\n",
        ")\n",
        "\n",
        "# train\n",
        "mlp_clf.fit(X_train, y_train)\n",
        "# mlp_reg.fit(X_train, y_train)\n",
        "\n",
        "# classification report\n",
        "y_pred = mlp_clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlM-U6woaJG-"
      },
      "outputs": [],
      "source": [
        "# 1. åˆ›å»ºåˆ†æå™¨\n",
        "analyzer = XAIAnalyzer(mlp_clf, X_train, class_names=le.classes_.tolist())\n",
        "\n",
        "# 2. æ‰§è¡Œå®Œæ•´åˆ†æï¼ˆæ¨èï¼‰\n",
        "analyzer.complete_xai_analysis(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AprPkwnQcvge"
      },
      "outputs": [],
      "source": [
        "#DNN\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # 2 hidded layer\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # 3 hidden layer\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    # outlayer\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=512,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Curves')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Curves')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-m8oAq03IgQ"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def predict_proba(model, X):\n",
        "    preds = model.predict(X)\n",
        "    # å¯¹äºäºŒåˆ†ç±»ï¼Œè¾“å‡ºä¸¤åˆ—ï¼Œæ¯åˆ—æ˜¯ä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
        "    proba = np.hstack([1 - preds, preds])  # 1 - preds æ˜¯ç¬¬ä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œpreds æ˜¯ç¬¬äºŒä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
        "    return proba\n",
        "\n",
        "# ç„¶åå°†æ¨¡å‹çš„ predict_proba æ–¹æ³•è®¾ç½®ä¸º predict_proba\n",
        "model.predict_proba = lambda X: predict_proba(model, X)\n",
        "\n",
        "def shap_plots(model, X_train, X_test, feature_names=None):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆæ¨¡å‹æ‰€æœ‰ç‰¹å¾çš„æ•´ä½“SHAPæ¡å½¢å›¾\n",
        "\n",
        "    å‚æ•°:\n",
        "    model: è®­ç»ƒå¥½çš„Kerasæ¨¡å‹\n",
        "    X_train: è®­ç»ƒé›†ç‰¹å¾æ•°æ®\n",
        "    X_test: æµ‹è¯•é›†ç‰¹å¾æ•°æ®\n",
        "    feature_names: ç‰¹å¾åç§°åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ\n",
        "    \"\"\"\n",
        "    print(\"æ­£åœ¨è®¡ç®—SHAPå€¼å¹¶ç”Ÿæˆæ¡å½¢å›¾...\")\n",
        "    print(f\"ç‰¹å¾æ•°é‡: {X_train.shape[1]}\")\n",
        "\n",
        "    # åˆ›å»ºç‰¹å¾åç§°\n",
        "    if feature_names is None:\n",
        "        feature_names = [f'Feature_{i}' for i in range(X_train.shape[1])]\n",
        "\n",
        "    # åˆ›å»ºSHAPè§£é‡Šå™¨ - ä½¿ç”¨DeepExplainerå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹\n",
        "    explainer = shap.Explainer(model, X_train[:100])  # ä½¿ç”¨å‰100ä¸ªæ ·æœ¬ä½œä¸ºèƒŒæ™¯æ•°æ®\n",
        "\n",
        "    # è®¡ç®—æµ‹è¯•é›†çš„SHAPå€¼\n",
        "    shap_values = explainer.shap_values(X_test[:1000])  # è®¡ç®—å‰500ä¸ªæµ‹è¯•æ ·æœ¬çš„SHAPå€¼\n",
        "\n",
        "    print(f\"SHAPå€¼å½¢çŠ¶: {shap_values.shape}\")\n",
        "\n",
        "    # ç”Ÿæˆæ¡å½¢å›¾\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    shap.summary_plot(shap_values, X_test[:1000],\n",
        "                     feature_names=feature_names,\n",
        "                     plot_type=\"bar\",\n",
        "                     show=False,\n",
        "                     max_display=min(20, len(feature_names)))  # æœ€å¤šæ˜¾ç¤º20ä¸ªç‰¹å¾\n",
        "    plt.title(\"SHAP Feature Importance - Bar Plot\", fontsize=16, fontweight='bold')\n",
        "    plt.xlabel(\"Mean |SHAP Value|\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"æ¡å½¢å›¾ç”Ÿæˆå®Œæˆï¼\")\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    shap.summary_plot(shap_values, X_test[:1000], feature_names=feature_names,show=False)\n",
        "    plt.title(\"SHAP Feature Importance - Beeswarm Plot\", fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"èœ‚ç¾¤å›¾ç”Ÿæˆå®Œæˆï¼\")\n",
        "\n",
        "\n",
        "\n",
        "def shap_waterfallplot_wrong_predictions(model, X_train, X_test, y_test, feature_names=None):\n",
        "    \"\"\"\n",
        "    ç”Ÿæˆäº”ä¸ªé”™è¯¯é¢„æµ‹æ ·æœ¬çš„SHAPç€‘å¸ƒå›¾\n",
        "\n",
        "    å‚æ•°:\n",
        "    model: è®­ç»ƒå¥½çš„Kerasæ¨¡å‹\n",
        "    X_train: è®­ç»ƒé›†ç‰¹å¾æ•°æ®\n",
        "    X_test: æµ‹è¯•é›†ç‰¹å¾æ•°æ®\n",
        "    y_test: æµ‹è¯•é›†çœŸå®æ ‡ç­¾\n",
        "    feature_names: ç‰¹å¾åç§°åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ\n",
        "    \"\"\"\n",
        "    print(\"æ­£åœ¨è¯†åˆ«é”™è¯¯é¢„æµ‹å¹¶ç”Ÿæˆç€‘å¸ƒå›¾...\")\n",
        "    print(f\"ç‰¹å¾æ•°é‡: {X_train.shape[1]}\")\n",
        "\n",
        "    # åˆ›å»ºç‰¹å¾åç§°\n",
        "    if feature_names is None:\n",
        "        feature_names = [f'Feature_{i}' for i in range(X_train.shape[1])]\n",
        "\n",
        "    # è·å–æ¨¡å‹é¢„æµ‹ - æ·»åŠ verbose=0å‡å°‘è¾“å‡º\n",
        "    y_pred_proba = model.predict(X_test, verbose=0)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "\n",
        "    # ç¡®ä¿y_testæ˜¯numpyæ•°ç»„\n",
        "    y_test_array = np.array(y_test).flatten()\n",
        "\n",
        "    # æ‰¾åˆ°é”™è¯¯é¢„æµ‹çš„ç´¢å¼•\n",
        "    wrong_indices = np.where(y_pred != y_test_array)[0]\n",
        "\n",
        "    if len(wrong_indices) == 0:\n",
        "        print(\"æœªå‘ç°é”™è¯¯é¢„æµ‹ï¼æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¡¨ç°å®Œç¾ã€‚\")\n",
        "        return\n",
        "\n",
        "    # é€‰æ‹©å‰5ä¸ªé”™è¯¯é¢„æµ‹ï¼ˆå¦‚æœä¸è¶³5ä¸ªåˆ™å…¨éƒ¨é€‰æ‹©ï¼‰\n",
        "    num_plots = min(5, len(wrong_indices))\n",
        "    selected_indices = wrong_indices[:num_plots]\n",
        "\n",
        "    print(f\"å‘ç° {len(wrong_indices)} ä¸ªé”™è¯¯é¢„æµ‹ï¼Œå°†å±•ç¤ºå‰ {num_plots} ä¸ªçš„ç€‘å¸ƒå›¾\")\n",
        "\n",
        "    # åˆ›å»ºSHAPè§£é‡Šå™¨\n",
        "    explainer = shap.DeepExplainer(model, X_train[:100])\n",
        "\n",
        "    explainer_lime = lime.lime_tabular.LimeTabularExplainer(\n",
        "                  X_train,\n",
        "                  feature_names=feature_names,\n",
        "                  class_names=le.classes_.tolist(),\n",
        "                  mode='classification'\n",
        "                  )\n",
        "\n",
        "    # ä¸ºæ¯ä¸ªé”™è¯¯é¢„æµ‹ç”Ÿæˆç€‘å¸ƒå›¾\n",
        "    for i, idx in enumerate(selected_indices):\n",
        "        print(f\"æ­£åœ¨ç”Ÿæˆç¬¬ {i+1} ä¸ªé”™è¯¯é¢„æµ‹çš„ç€‘å¸ƒå›¾...\")\n",
        "\n",
        "        try:\n",
        "            # è®¡ç®—å•ä¸ªæ ·æœ¬çš„SHAPå€¼\n",
        "            sample_shap_values = explainer.shap_values(X_test[idx:idx+1])\n",
        "\n",
        "            # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®\n",
        "            shap_vals = np.array(sample_shap_values).flatten()\n",
        "            feature_vals = np.array(X_test[idx]).flatten()\n",
        "\n",
        "            print(f\"SHAPå€¼æ•°é‡: {len(shap_vals)}, ç‰¹å¾å€¼æ•°é‡: {len(feature_vals)}\")\n",
        "\n",
        "            # è·å–é¢„æµ‹ä¿¡æ¯\n",
        "            true_label = int(y_test_array[idx])\n",
        "            pred_proba = float(y_pred_proba[idx][0])\n",
        "            pred_label = int(y_pred[idx])\n",
        "\n",
        "            # å¤„ç†base_values\n",
        "            base_val = float(explainer.expected_value)\n",
        "\n",
        "            # ç”Ÿæˆç€‘å¸ƒå›¾\n",
        "            plt.figure(figsize=(12, 8))\n",
        "\n",
        "            # åˆ›å»ºExplanationå¯¹è±¡ç”¨äºç€‘å¸ƒå›¾\n",
        "            explanation = shap.Explanation(\n",
        "                values=shap_vals,\n",
        "                base_values=base_val,\n",
        "                data=feature_vals,\n",
        "                feature_names=feature_names\n",
        "            )\n",
        "\n",
        "            shap.waterfall_plot(explanation, show=False, max_display=10)\n",
        "            plt.title(f\"index #{idx} - true label: {true_label}, prediction: {pred_label}, prob: {pred_proba:.3f}\",\n",
        "                     fontsize=14, fontweight='bold')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            exp = explainer_lime.explain_instance(X_test[idx], model.predict_proba, num_features=10)\n",
        "            exp.show_in_notebook(show_table=True)\n",
        "        except Exception as e:\n",
        "            print(f\"ç”Ÿæˆç¬¬ {i+1} ä¸ªç€‘å¸ƒå›¾æ—¶å‡ºé”™: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(\"ç€‘å¸ƒå›¾ç”Ÿæˆå®Œæˆï¼\")\n",
        "\n",
        "\n",
        "# ä½¿ç”¨ç¤ºä¾‹å‡½æ•°\n",
        "def run_shap_analysis(model, X_train, X_test, y_test, feature_names=None):\n",
        "    \"\"\"\n",
        "    è¿è¡Œå®Œæ•´çš„SHAPåˆ†æ\n",
        "\n",
        "    å‚æ•°:\n",
        "    model: è®­ç»ƒå¥½çš„Kerasæ¨¡å‹\n",
        "    X_train: è®­ç»ƒé›†ç‰¹å¾æ•°æ®\n",
        "    X_test: æµ‹è¯•é›†ç‰¹å¾æ•°æ®\n",
        "    y_test: æµ‹è¯•é›†çœŸå®æ ‡ç­¾\n",
        "    feature_names: ç‰¹å¾åç§°åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"å¼€å§‹SHAPå¯è§£é‡Šæ€§åˆ†æ\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. ç”Ÿæˆæ¡å½¢å›¾\n",
        "    print(\"\\n1. ç”Ÿæˆç‰¹å¾é‡è¦æ€§...\")\n",
        "    shap_plots(model, X_train, X_test, feature_names)\n",
        "\n",
        "    # 3. ç”Ÿæˆé”™è¯¯é¢„æµ‹çš„ç€‘å¸ƒå›¾\n",
        "    print(\"\\n3. ç”Ÿæˆé”™è¯¯é¢„æµ‹çš„ç€‘å¸ƒå›¾...\")\n",
        "    shap_waterfallplot_wrong_predictions(model, X_train, X_test, y_test, feature_names)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"SHAPåˆ†æå®Œæˆï¼\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# ä½¿ç”¨æ–¹æ³•:\n",
        "# ç¡®ä¿å·²å®‰è£…shap: pip install shap\n",
        "#\n",
        "# å¦‚æœæ‚¨æœ‰ç‰¹å¾åç§°åˆ—è¡¨ï¼š\n",
        "feature_names = X.columns.to_list()  # æ‚¨çš„å®é™…ç‰¹å¾åç§°\n",
        "#\n",
        "# è°ƒç”¨å•ä¸ªå‡½æ•°:\n",
        "# shap_barplots(model, X_train, X_test, feature_names)\n",
        "# shap_beeswarmplot(model, X_train, X_test, feature_names)\n",
        "# shap_waterfallplot_wrong_predictions(model, X_train, X_test, y_test, feature_names)\n",
        "#\n",
        "# æˆ–è¿è¡Œå®Œæ•´åˆ†æ:\n",
        "run_shap_analysis(model, X_train, X_test, y_test, feature_names)\n",
        "#\n",
        "# å¦‚æœæ²¡æœ‰ç‰¹å¾åç§°ï¼Œä¼šè‡ªåŠ¨ç”ŸæˆFeature_0, Feature_1ç­‰åç§°"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_proba(model, X):\n",
        "    preds = model.predict(X)\n",
        "    # å¯¹äºäºŒåˆ†ç±»ï¼Œè¾“å‡ºä¸¤åˆ—ï¼Œæ¯åˆ—æ˜¯ä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
        "    proba = np.hstack([1 - preds, preds])  # 1 - preds æ˜¯ç¬¬ä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œpreds æ˜¯ç¬¬äºŒä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
        "    return proba\n",
        "\n",
        "# ç„¶åå°†æ¨¡å‹çš„ predict_proba æ–¹æ³•è®¾ç½®ä¸º predict_proba\n",
        "model.predict_proba = lambda X: predict_proba(model, X)\n",
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "                  X_train,\n",
        "                  feature_names=feature_names,\n",
        "                  class_names=le.classes_.tolist(),\n",
        "                  mode='classification'\n",
        "                  )\n",
        "exp = explainer.explain_instance(X_test[7233], model.predict_proba, num_features=)\n",
        "exp.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "CTc1yID4_lzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDiGpTcmev1i"
      },
      "outputs": [],
      "source": [
        "#XGBoost\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "xgb_clf = XGBClassifier(\n",
        "    # objective='multi:softmax',\n",
        "    objective='binary:logistic',\n",
        "    n_estimators=200,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    eval_metric='logloss',\n",
        "    early_stopping_rounds=10,\n",
        "    scale_pos_weight=1\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "y_proba = xgb_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# evaluation\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8by1NN3Il0YG"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Solution 1: Use TreeExplainer instead of KernelExplainer (Recommended)\n",
        "def shap_plots_fixed(model, X_train, X_test):\n",
        "    \"\"\"\n",
        "    Fixed version using TreeExplainer which is more efficient and compatible\n",
        "    \"\"\"\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer.shap_values(X_test[:1000])\n",
        "\n",
        "    # For binary classification, shap_values might be a list or 2D array\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[1]  # Use positive class\n",
        "    elif len(shap_values.shape) == 3:\n",
        "        shap_values = shap_values[:, :, 1]  # Use positive class\n",
        "\n",
        "    shap.summary_plot(shap_values, X_test[:1000], plot_type=\"bar\")\n",
        "    shap.summary_plot(shap_values, X_test[:1000])\n",
        "\n",
        "\n",
        "def lime_plot(model, X_train, X_test,Y_train, row_index,class_names):\n",
        "    import lime\n",
        "    import lime.lime_tabular\n",
        "    # Create a Lime explainer object\n",
        "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_train.values,\n",
        "    training_labels=Y_train,\n",
        "    feature_names=X_train.columns.tolist(),\n",
        "    class_names=class_names,\n",
        "    mode='classification'\n",
        "    )\n",
        "\n",
        "    exp = explainer.explain_instance(X_test.iloc[row_index], model.predict_proba, num_features=len(X_train.columns))\n",
        "    exp.show_in_notebook(show_table=True)\n",
        "\n",
        "def shap_waterfallplot_wrong_predictions_fixed(model, X_train, X_test, y_test,Y_train,class_names):\n",
        "    \"\"\"\n",
        "    Fixed version for waterfall plots\n",
        "    \"\"\"\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Find wrong predictions\n",
        "    wrong_indices = np.where(y_pred != y_test)[0]\n",
        "\n",
        "    if len(wrong_indices) == 0:\n",
        "        print(\"No wrong predictions found!\")\n",
        "        return\n",
        "\n",
        "    # Show waterfall plot for first wrong prediction\n",
        "    num_plots = min(5, len(wrong_indices))\n",
        "    selected_indices = wrong_indices[:num_plots]\n",
        "\n",
        "    for i, idx in enumerate(selected_indices):\n",
        "        print(f\"Generating waterfall plot for index {idx}...\")\n",
        "        # Handle different shap_values formats\n",
        "        if isinstance(shap_values, list):\n",
        "            shap_vals = shap_values[1][idx]  # Use positive class\n",
        "        elif len(shap_values.shape) == 3:\n",
        "            shap_vals = shap_values[idx, :, 1]  # Use positive class\n",
        "        else:\n",
        "            shap_vals = shap_values[idx]\n",
        "\n",
        "    # Create explanation object for waterfall plot\n",
        "        explanation = shap.Explanation(\n",
        "            values=shap_vals,\n",
        "            base_values=explainer.expected_value if not isinstance(explainer.expected_value, list) else explainer.expected_value[1],\n",
        "            data=X_test.iloc[idx] if hasattr(X_test, 'iloc') else X_test[idx]\n",
        "        )\n",
        "\n",
        "        shap.waterfall_plot(explanation)\n",
        "        lime_plot(model, X_train, X_test,Y_train, idx,class_names)\n",
        "\n",
        "\n",
        "# Updated function calls - replace your original functions with these:\n",
        "def run_shap_analysis(model, X_train, X_test, y_test,Y_train,class_names):\n",
        "    \"\"\"\n",
        "    Run all SHAP analyses with fixed functions\n",
        "    \"\"\"\n",
        "    print(\"Creating bar plots...\")\n",
        "    shap_plots_fixed(model, X_train, X_test)\n",
        "\n",
        "    print(\"Creating waterfall plots for wrong predictions...\")\n",
        "    shap_waterfallplot_wrong_predictions_fixed(model, X_train, X_test, y_test,Y_train,class_names)\n",
        "\n",
        "# Usage example:\n",
        "class_names = le.classes_.tolist()\n",
        "run_shap_analysis(xgb_clf, X_train, X_test, y_test,y_train,class_names)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tWB8tx2CZnexlY3B-uhwMZP-y89YESbq",
      "authorship_tag": "ABX9TyN7hekdUdgsc9UHHGu7qAK4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}